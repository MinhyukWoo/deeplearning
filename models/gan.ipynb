{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 200\n",
    "batch_size = 100\n",
    "sample_dir = 'samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CarDataset at 0x7f5573dbb6d0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils import data\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "\n",
    "class CarDataset(data.Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.data_dir = os.path.join(os.pardir, 'dataset', 'cars_images')\n",
    "        self.filenames = os.listdir(self.data_dir)\n",
    "        self.to_tensor = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ]) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        torch.zeros((360, 360))\n",
    "        return self.to_tensor(Image.open(os.path.join(self.data_dir, self.filenames[index])).resize((256, 256), Image.BICUBIC))\n",
    "\n",
    "car_dataset = CarDataset()\n",
    "car_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m car_data_loader \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mDataLoader(dataset\u001b[39m=\u001b[39mcar_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m car \u001b[39min\u001b[39;00m car_data_loader:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "car_data_loader = data.DataLoader(dataset=car_dataset, batch_size=32, shuffle=True)\n",
    "for car in car_data_loader:\n",
    "    print(car.shape)\n",
    "    plt.imshow(car[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1, *args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, **kwargs),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[16, 16]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels, image_size, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.convs = nn.Sequential(\n",
    "            ConvBlock(in_channels, 128),\n",
    "            ConvBlock(128, 256),\n",
    "            ConvBlock(256, 512),\n",
    "            ConvBlock(512, 1024),\n",
    "        )\n",
    "        img_size = list(image_size)\n",
    "        for _ in range(len(self.convs)):\n",
    "            for idx in range(len(img_size)):\n",
    "                img_size[idx] //= 2\n",
    "\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024 * img_size[0] * img_size[1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = self.classify(x)\n",
    "        return x\n",
    "\n",
    "discriminator = Discriminator(3, (256, 256))\n",
    "\n",
    "discriminator(torch.zeros((4, 3, 256, 256), dtype=torch.float)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size, image_size, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.convs = nn.Sequential(\n",
    "            ConvBlock(latent_size, 1024),\n",
    "            ConvBlock(1024, 512),\n",
    "            ConvBlock(512, 256),\n",
    "            ConvBlock(256, 3),\n",
    "        )\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024 * image_size[0] * image_size[1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(latent_size, )\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = self.classify(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ff13a2780294b00c288ae574505f38e9bd67ad73899839bae0a58c5d9821089"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
