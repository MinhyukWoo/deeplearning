{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicConv2d(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False, **kwargs),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "BasicConv2d(3, 32, 3, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicConvTranspose2d(\n",
       "  (layers): Sequential(\n",
       "    (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BasicConvTranspose2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding, bias=False, **kwargs),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "BasicConvTranspose2d(64, 32, 3, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureEncoder(\n",
      "  (layers): Sequential(\n",
      "    (0): BasicConv2d(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicConv2d(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicConv2d(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicConv2d(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): BasicConv2d(\n",
      "      (layers): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 2, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeatureEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=512) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            BasicConv2d(in_channels, 32),\n",
    "            BasicConv2d(32, 64),\n",
    "            BasicConv2d(64, 128),\n",
    "            BasicConv2d(128, 256),\n",
    "            BasicConv2d(256, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "print(FeatureEncoder())\n",
    "FeatureEncoder()(torch.ones((4, 3, 64, 64), dtype=torch.float)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureDecoder(\n",
      "  (layers): Sequential(\n",
      "    (0): BasicConvTranspose2d(\n",
      "      (layers): Sequential(\n",
      "        (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicConvTranspose2d(\n",
      "      (layers): Sequential(\n",
      "        (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicConvTranspose2d(\n",
      "      (layers): Sequential(\n",
      "        (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicConvTranspose2d(\n",
      "      (layers): Sequential(\n",
      "        (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): BasicConvTranspose2d(\n",
      "      (layers): Sequential(\n",
      "        (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 64, 64])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeatureDecoder(nn.Module):\n",
    "    def __init__(self, in_channels=512, out_channels=32) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            BasicConvTranspose2d(in_channels, 256),\n",
    "            BasicConvTranspose2d(256, 128),\n",
    "            BasicConvTranspose2d(128, 64),\n",
    "            BasicConvTranspose2d(64, 32),\n",
    "            BasicConvTranspose2d(32, out_channels),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "print(FeatureDecoder())\n",
    "FeatureDecoder()(torch.ones((4, 512, 2, 2), dtype=torch.float)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentVectorConverter(nn.Module):\n",
    "    def __init__(self, in_features, latent_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.mu_linear = nn.Linear(in_features, latent_dim)\n",
    "        self.var_linear = nn.Linear(in_features, latent_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        mu = self.mu_linear(x)\n",
    "        var = self.var_linear(x)\n",
    "        std = torch.exp(0.5 * var)\n",
    "        z = mu + std * torch.randn_like(std)\n",
    "        return z, mu, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (feature_encoder): FeatureEncoder(\n",
      "    (layers): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicConv2d(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): BasicConv2d(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (4): BasicConv2d(\n",
      "        (layers): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (latent_vector_converter): LatentVectorConverter(\n",
      "    (mu_linear): Linear(in_features=2048, out_features=128, bias=True)\n",
      "    (var_linear): Linear(in_features=2048, out_features=128, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=512, latent_dim=128) -> None:\n",
    "        super().__init__()\n",
    "        self.feature_encoder = FeatureEncoder(in_channels, out_channels)\n",
    "        out_img_size = 2\n",
    "        self.latent_vector_converter = LatentVectorConverter(\n",
    "            out_img_size * out_img_size * out_channels, latent_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_encoder(x)\n",
    "        x, mu, std = self.latent_vector_converter(x)\n",
    "        return x, mu, std\n",
    "\n",
    "\n",
    "print(Encoder())\n",
    "outs = Encoder()(torch.ones((4, 3, 64, 64), dtype=torch.float))\n",
    "for out in outs:\n",
    "    print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder(\n",
      "  (z_linear): Linear(in_features=128, out_features=2048, bias=True)\n",
      "  (feature_decoder): FeatureDecoder(\n",
      "    (layers): Sequential(\n",
      "      (0): BasicConvTranspose2d(\n",
      "        (layers): Sequential(\n",
      "          (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicConvTranspose2d(\n",
      "        (layers): Sequential(\n",
      "          (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BasicConvTranspose2d(\n",
      "        (layers): Sequential(\n",
      "          (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): BasicConvTranspose2d(\n",
      "        (layers): Sequential(\n",
      "          (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (4): BasicConvTranspose2d(\n",
      "        (layers): Sequential(\n",
      "          (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (last_layer): Sequential(\n",
      "    (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 64, 64])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=128, in_img_size=2, in_channels=512, out_channels=3) -> None:\n",
    "        super().__init__()\n",
    "        self.in_img_size = in_img_size\n",
    "        self.in_channels = in_channels\n",
    "        self.z_linear = nn.Linear(latent_dim, in_img_size * in_img_size * in_channels)\n",
    "        self.feature_decoder = FeatureDecoder(in_channels, 32)\n",
    "        self.last_layer = nn.Sequential(\n",
    "            nn.Conv2d(32, out_channels, 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.z_linear(x)\n",
    "        x = x.reshape((-1, self.in_channels, self.in_img_size, self.in_img_size))\n",
    "        x = self.feature_decoder(x)\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "\n",
    "print(Decoder())\n",
    "Decoder()(torch.ones((16, 128), dtype=torch.float)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vae(\n",
      "  (encoder): Encoder(\n",
      "    (feature_encoder): FeatureEncoder(\n",
      "      (layers): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (layers): Sequential(\n",
      "            (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (layers): Sequential(\n",
      "            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): BasicConv2d(\n",
      "          (layers): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): BasicConv2d(\n",
      "          (layers): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (4): BasicConv2d(\n",
      "          (layers): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (latent_vector_converter): LatentVectorConverter(\n",
      "      (mu_linear): Linear(in_features=2048, out_features=128, bias=True)\n",
      "      (var_linear): Linear(in_features=2048, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (z_linear): Linear(in_features=128, out_features=2048, bias=True)\n",
      "    (feature_decoder): FeatureDecoder(\n",
      "      (layers): Sequential(\n",
      "        (0): BasicConvTranspose2d(\n",
      "          (layers): Sequential(\n",
      "            (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicConvTranspose2d(\n",
      "          (layers): Sequential(\n",
      "            (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): BasicConvTranspose2d(\n",
      "          (layers): Sequential(\n",
      "            (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): BasicConvTranspose2d(\n",
      "          (layers): Sequential(\n",
      "            (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (4): BasicConvTranspose2d(\n",
      "          (layers): Sequential(\n",
      "            (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (last_layer): Sequential(\n",
      "      (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "  x: torch.Size([16, 3, 64, 64])\n",
      " mu: torch.Size([16, 128])\n",
      "std: torch.Size([16, 128])\n"
     ]
    }
   ],
   "source": [
    "class Vae(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, mu, std = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x, mu, std\n",
    "\n",
    "model = Vae()\n",
    "print(model)\n",
    "x, mu, std = model(torch.ones((16, 3, 64, 64), dtype=torch.float))\n",
    "print('  x:', x.shape)\n",
    "print(' mu:', mu.shape)\n",
    "print('std:', std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(302.3123, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class KLDivergenceLoss(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, pred, target, mu, std):\n",
    "        reconst_err = self.mse(pred, target)\n",
    "        regular_err = torch.sum(std ** 2 + mu ** 2 - torch.log(std ** 2) - 1) * 0.5\n",
    "        return -1 * reconst_err + regular_err\n",
    "    \n",
    "loss = KLDivergenceLoss()\n",
    "loss(x, x, mu, std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
